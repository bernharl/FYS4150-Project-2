\documentclass[twocolumn]{aastex62}


\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\begin{document}

\title{Solving Eigenvalue Problems by Means of the Jacobi Algorithm}

\author{Håkon Tansem}

\author{Nils-Ole Stutzer}

\author{Bernhard Nornes Lotsberg}

\begin{abstract}

We implement the Jacobi algorithm for solving eigenvalue problems and apply it to three different physical systems; the buckling beam, single- and double- electron quantum harmonic oscillators in three dimensions. For the buckling beam, we see that the number of similarity transformations needed grows proportionally to $O(n^2)$ as expected  (\cite{Jensen:2015}), and the relative errors between the three first computed and analytical eigenvalues increase before settling on an almost constant value. For the single electron harmonic oscillator, in order to reproduce the analytical eigenvalues within a four digit margin, we find that $\rho_{max}\approx 5.27$ gives the best compromise in precision for the first four eigenvalues. In the case of two Coulomb-interacting electrons, we find that the ground state energy-eigenvalues increase with increasing potential strength $\omega_r$ and that for $\omega_r=0.05$ and $\omega_r=0.25$, our numerical results $\lambda_1^{\omega_r=0.05}\approx 0.475$ and $\lambda_1^{\omega_r=0.25}\approx 1.250$ are consistent with analytical eigenvalues (\cite{taut:1993}) \\\\
 The source codes for this paper can be found at
 \href{https://github.com/bernharl/FYS4150-Project-2}{https://github.com/bernharl/FYS4150-Project-2}.
\end{abstract}

\section{Introduction} \label{sec:intro}
When solving physical and mathematical problems, a recurring problem is to find eigenvalues of a matrix or an operator. Since a wide variety of problems can be solved by setting up and solving eigenvalue equations it is, essential to develop efficient methods for finding eigenvalues. 

In this paper we will show how an eigenvalue solver implementing Jacobi's algorithm, as described by \citep[Ch. 7.4]{Jensen:2015}, can be used to solve problems like the eigenmodes of the classical wave equation and the eigenenergies of the Schrödinger equation for one or two electron in a harmonic oscillator potential. Both problems can be rescaled in such a way that the resulting equations are on dimensionless form. On this generalized, dimensionless form, it covers several physical eigenvalue problems, making this a very versatile method. We will explore how the numerical and analytical eigenvalues of the problems illustrated compare and how the run time of the Jacobi algorithm varies with different grid sizes.

Our method section states needed theory and outlines the physical problems to be solved and the strategies we employ to solve them. The results produced are presented in the results section and discussed in the discussion section.   

\section{Method} \label{sec:method}
\subsection{Classical Wave - The Buckling Beam Problem}
The first example of an eigenvalue problem we present is the classical wave equation for a buckling beam in one dimension
\begin{align}
	\gamma\dv[2]{u(x)}{x} = -F(x)u(x).
	\label{eq:beam_wave}
\end{align} 
Here $u(x)$ represents the vertical displacement of the beam along the $y$-direction. We let $x\in[0,L]$ for a beam length $L$. The constant $\gamma$ is a material dependent parameter specifying the beams rigidity and $F$ is the force applied at the interval $(0, L)$. Next the Dirichlet boundary conditions are imposed so that $u(0) = u(L) = 0$. We consider the three parameters $F$, $L$ and $\gamma$ to be known.
In order to make the equation more convenient to handle, we scale the integration variable to the beam length as 
\begin{align}
	\rho = \frac{x}{L},
\end{align}
so that the new dimensionless integration variable $\rho\in[0, 1]$. We can now rewrite (\ref{eq:beam_wave}) as 
\begin{align}
	\dv[2]{u(\rho)}{\rho} = -\frac{FL^2}{\gamma}u(\rho) = -\lambda u(\rho),
	\label{eq:wave_eq_dimless}
\end{align}
where we define $\lambda = \frac{FL^2}{\gamma}$. In order to solve (\ref{eq:wave_eq_dimless}) for the $\lambda$'s numerically the discretization $\rho\to\rho_i = \rho_0 + ih$  is introduced, where with $i = 0, 1, 2, 3, \ldots n-1$. The equation written on discrete form is then

\begin{align}
	\dv[2]{u_i}{x} &\approx
	-\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} = \lambda u_i ,
\end{align}
where the step length $h = \frac{\rho_n - \rho_0}{n}$, $\rho_0 = \rho_\text{min} = 0$ and $\rho_n = \rho_\text{max} = 1$ are the boundaries and $n$ is the grid size. Here $u_{i\pm1}$ denotes $u(\rho_i\pm h)$.

The above discrete equation can easily be fomulated as a matrix equation 
\begin{align}
	A\vec{u} = \lambda\vec{u},
	\label{eq:matrix_eq}
\end{align}
by introducing the vector $\vec{u}^T = [u_1, u_2, \ldots, u_{n-1}]$ and the matrix
\begin{align}
A = 
	\begin{bmatrix} 
	d& a & 0   & 0    & \dots  &0     & 0 \\
    a & d & a & 0    & \dots  &0     &0 \\
    0   & a & d & a  &0       &\dots & 0\\
    \dots  & \dots & \dots & \dots  &\dots      &\dots & \dots\\
    0   & \dots & \dots & \dots  &a  &d & a\\
   0   & \dots & \dots & \dots  &\dots       &a & d
    \end{bmatrix} ,
\end{align}
where $a = -\frac{1}{h^2}$ and $d = \frac{2}{h^2}$.
The problem is now transformed into a linear algebra eigenvalue problem.  Since the analytical eigenvalues 
\begin{align}\label{eq:analyticaleig}
	\lambda_i = d + 2a \cos\left(\frac{j\pi}{n+1}\right)\quad j = 1, 2, 3, \ldots n,
\end{align}
are known we can later compare these to those found numerically.

\subsection{Eigenvalue Solver - Jacobi's Algorithm}
\label{sec:Jacobi}
The eigenvalue solver we will show applies the Jacobi algorithm, which converges quite stably, yet very slowly. The essence of the algorithm is that we can rotate the column space of $A$ around different axes in the $n$ dimensional space using similarity transforms, obtaining a diagonal matrix $D$ being similar to $A$. Due to the similarity between $D$ and $A$, the diagonal elements $d_{ii} = \lambda_i$, being the eigenvalues of $D$, are also eigenvalues of $A$.

The similarity transforms used in the Jacobi algorithm is based on a sequence of orthogonal transforms. In an orthogonal transformation an orthogonal basis $F = \{\vec{v}_i | i = 1, 2, \ldots, n\}$, keeps its orthogonality. Meaning that the basis vectors in the new basis $G = \{\vec{w}_i | i = 1, 2, \ldots, n\}$ where $\vec{w}_i = U\vec{v}_i$ form a new orthogonal basis for the same space as before the transformation if $U$ is orthogonal i.e. $UU^T = U^TU = I_n$ giving $U^{-1} = U^T$. Therefore the inner product of basis vectors in $G$ give 
\begin{align}
	\vec{w}_i\cdot \vec{w}_j &= w_i^Tw_j = (Uv_i)^T(Uv_j) \\
	&= v_i^TU^TUv_j = v_i^Tv_j = \delta_{ij},
\end{align}
due to the orthogonality of the basis $F$.

When transforming $A$ into a diagonal matrix $D$ we need to eliminate the off-diagonal elements of $A$. A single similarity transform $B$ of the matrix $A$ is written as
\begin{align}
	B = S^T A S
\end{align}
for a rotational matrix 
\begin{align}
S = 
	\begin{bmatrix}
		1 & 0 & 0 & 0 & \cdots & 0\\
		0 & 1 & 0 & 0 & \cdots & 0 \\	
		\vdots & & \ddots & & & \vdots \\
		0 & & \cos\theta & \cdots & \sin\theta & 0\\
		\vdots & & & & & \vdots \\
		0 & & -\sin\theta & \cdots & \cos\theta & 0\\
		\vdots & & \ddots & & & \vdots \\
		0 & 0 & 0 & 0 & 1 & 0\\		
		0 & 0 & 0 & 0 & 0 & 1
	\end{bmatrix},
\end{align}
rotating the column space basis an angle $\theta$ in the $\rho_k$-$\rho_l$-plane, since $S_{kk} = S_{ll} = \cos\theta = c$, $S_{kl} = \sin\theta = s = -S_{lk}$. Since the rotational matrix $S$ is orthogonal, the matrix $B$ is similar to $A$.

Multiplying out the above similarity transform we get 
\begin{align}
	b_{ii} &= a_{ii} , i\neq k, i\neq l\\
	b_{ik} &= a_{ik}c - a_{il}s, i\neq k, i\neq l\\
	b_{il} &= a_{il}c + a_{ik}s, i\neq k, i\neq l\\
	b_{kk} &= a_{kk}c^2 - 2a_{kl}cs + a_{ll}s^2\\
	b_{ll} &= a_{ll}c^2 + 2a_{kl}cs + a_{kk}s^2\\
	b_{kl} &= (a_{kk} - a_{ll})cs + a_{kl}(c^2 - s^2).
	\label{eq:b_kl}
\end{align}
Since we want to zero out the off-diagonals of $A$ we require that (\ref{eq:b_kl}) is zeroed out, i.e. $b_{kl} = b_{lk} = 0$. Defining 
\begin{align}
	\cot(2\theta) = \tau = \frac{a_{ll} - a_{kk}}{2a_{kl}}
\end{align}
we get a quadratic equation $t^2 + 2\tau t - 1 = 0$, where $t = \tan \theta$, following the requirement $b_{kl} = 0$. From this quadratic equation we get that 
\begin{align}
	t &= -\tau \pm \sqrt{1+\tau^2}\\
	c & = \frac{1}{\sqrt{1+t^2}}\\
	s &= tc.
\end{align}
This way we can tune the angle $\theta$ in order to zero out $b_{kl}$ and then find the remaining elements of $B$.  The way $t$ is defined is numerically unstable. If $\tau\gg1$ a computer will let $1+\tau^2 = \tau^2$ resulting in $t = -\tau \pm \tau$ which is not correct. Using some simple algebra we rewrite $t = -\frac{1}{-\tau \pm \sqrt{1 + \tau^2}}$, which is more numerically stable. Let $t = \frac{1}{\tau + \sqrt{1 + \tau^2}}$ whenever $\tau>0$ and let $t = -\frac{1}{-\tau + \sqrt{1+\tau^2}}$ when $t<0$, thus circumventing  subtraction of almost equal numbers in the denominator which can resulting in division by zero.

As shown by \citep[Ch. 7.4]{Jensen:2015} for a $2\time 2$-matrix w.l.o.g., the off-diagonal norm of a similarity transform $B$ is 
\begin{align}
\text{Off}(B)^2&= \sum_{i\neq j} |b_{ij}^2| = ||A||_F^2 - 2a_{kl},
\label{eq:Off_reduction}
\end{align}
being reduced in size for each transform. To determine which elements $a_{kl}$ should be eliminated each time we perform a similarity transform, we look at (\ref{eq:Off_reduction}); if we choose $a_{kl}$ to be the greatest off-diagonal element of $A$ we reduce $\text{Off}(B)^2$ by the largest possible value for each iteration. 

Since we want to end up with a diagonal matrix $D$ we need to make the off-diagonal norm approach zero through multiple similarity transforms. In practice this corresponds to iterate over similarity transforms, until 
\begin{align}
\text{Off}(A) \geq \max_{i\neq j}(a_{ij}^2) = a_{kl}^2 \leq \epsilon,
\end{align}
for a tolerance $\epsilon$ typically $\sim 10^{-8}$. We can thus use 
$\max_{i\neq j}(a_{ij}^2)\leq \epsilon$ as a stopping criterion for the while loop performing the similarity transforms, instead of calculating $\text{Off}(A)$ which can be time consuming.

After having looped over the similarity transforms the remaining matrix should be diagonal withing the tolerance, making it easy to extract the eigenvalues $\lambda_i$. To find the corresponding eigenvectors, we rotate an arbitrary orthogonal basis for $\mathcal{R}^n$ for each loop iteration using the corresponding rotation $S$. We then contain the input basis vectors in a matrix $E$, e.g. the identity matrix, and rotate them one rotation by multiplying $SE$. This is also done in the loop so that 
\begin{align}
	e_{ik} &= ce_{ik} - se_{il}\\
	e_{il} &= ce_{il} + se_{ik}.
\end{align}

As discussed by \citep[p. 217]{Jensen:2015} the Jacobi algorithm usually requires between $3n^2-5n^2$ rotations, and each rotation requires $\sim 4n$ operations, resulting in $13n^3-20n^3$ operations to zero out the off-diagonal elements. Since we only consider sparse matrices in our case, we expect $\sim n$ rotations needed to diagonalize. 

The Jacobi algorithm can now be used to solve eigenvalue problems for symmetrical matrices like the buckling beam wave or quantum mechanical problems as shown in the following subsection. 

\begin{figure*}[h]
	\plotone{{Figures/eigenrelerr}.eps}
	\caption{Figure showing the relative error between the numerical and analytical eigenvalues, given by equation \ref{eq:analyticaleig}, as a function of $n$ for the buckling beam problem given by (\ref{eq:matrix_eq}). Here $n$ starts at $n=3$. }
	\label{fig:relerr}
\end{figure*}

\begin{figure*}[h]
	\plotone{{Figures/iteration}.eps}
	\caption{Figure showing the number of similarity transforms conducted before the off-diagonal elements are set below a tolerance when solving the buckling beam problem using the Jacobi algorithm.}
	\label{fig:iteration}
\end{figure*}

\subsection{Schrödinger's Equation - One Electron in a Harmonic Oscillator potential}

\label{sec:SEharmosc}
Next we show how to apply the Jacobi algorithm to find the energy eigenvalues of the Hamiltonian operator for an electron in a harmonic oscillator potential $V(r)$ in three dimensions. For simplicity we only consider the radial Schrödinger equation 
\begin{align}
-\frac{\hbar^2}{2m}\left(\frac{1}{r^2}\dv{r}r^2\dv{r} - \frac{l(l+1)}{r^2}\right)R(r) + V(r)R(r) = E R(r),
\end{align}
where $V(r) = \frac{1}{2}kr^2$ with $k = m\omega^2$, and the energies $E$ of the electron in the harmonic oscillator in three dimensions are given as 
\begin{align}
	E_{nl} = \hbar\omega\left(2n + l + \frac{3}{2}\right),
\end{align}
where $n = 0, 1, 2,\ldots$ and $l = 0, 1, 2, \ldots$, representing the principal and orbital momentum quantum numbers. We let the radial distance $r\in[0,\infty)$. Next we let $R(r) = \frac{u(r)}{r}$ so that 
\begin{align}
	-\frac{\hbar^2}{2m}\dv[2]{r}u(r) + \left(V(r) + \frac{l(l+1)}{r^2}\frac{\hbar^2}{2m}\right)u(r) = Eu(r).
	\label{eq:u_r}
\end{align}
In order to reflect reality we must require $u(0) = u(\infty) = 0$, as the wave function of the electron must fall of to zero when going to infinity. 

To ensure safer handling of the equation we introduce the dimensionless radial distance $\rho = \frac{r}{\alpha}$, where $\alpha$ is a parameter with dimension length. Inserting this into (\ref{eq:u_r}) we obtain
\begin{align}
	-\frac{\hbar^2}{2m\alpha^2}\dv[2]{\rho}u(\rho) + \left(V(\rho) + \frac{l(l+1)}{\rho^2}\frac{\hbar^2}{2m\alpha^2}\right)u(\rho) = Eu(\rho).
	\label{eq:schrodinger_rho}
\end{align}
To simplify things further we only consider the case where $l=0$. Inserting the dimensionless potential $V(\rho) = \frac{k}{2}\alpha^2\rho^2u(\rho)$ into (\ref{eq:schrodinger_rho}) we can rewrite the equation as 
\begin{align}
	-\frac{\hbar^2}{2m\alpha^2} \dv[2]{\rho} u(\rho) + \frac{k}{2}\alpha^2\rho^2u(\rho) = Eu(\rho),
\end{align}
by multiplying both sides by $\frac{2m\alpha^2}{\hbar^2}$.
In order to simplify things even further we introduce a natural length scale so that 
\begin{align}
	\alpha = \left(\frac{\hbar^2}{mk}\right)^{1/4},
\end{align}
being set by the mass of the electron $m$ and the strength potential $k$ and we let the frequency $\omega = 1$.
The energy eigenvalues are then defined as 
\begin{align}
	\lambda = \frac{2m\alpha^2}{\hbar^2}E.
\end{align}

The Schrödinger equation is now on a dimensionless form 
\begin{align}
	-\dv[2]{\rho}u(\rho) + \rho^2u(\rho) = \lambda u(\rho),
	\label{eq:schrodinger_dimless}
\end{align}
where $V(\rho)=\rho^2$ represents the effective potential.
To solve for the eigenvaules numerically we discretize the equation so that 
\begin{align}
	&-\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} + \rho_i^2 u_i \\
	&= -\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} + V_iu_i = \lambda u_i, 
\end{align}
letting the effective potential $V_i = \rho_i^2$. The step size $h$ has the same form as shown earlier only for a different $\rho_n$. Since we need the wave function $u(\rho)$ to tend to zero at infinity, $\rho\to \infty$, we must set $\rho_{max} =\rho_n= \infty$. However, representing infinity on a computer is not possible, meaning we need to find a suitably large number to approximate infinity. The approximation of infinity will also be dependent on the matrix size, meaning we have to balance our choice of parameters $\rho_{max}$ and $n$ in order to achieve the wanted precision in the eigenvalues. From this discretization we can write the equation on the same matrix form as (\ref{eq:matrix_eq}), this time using diagonal elements $d_i = \frac{2}{h^2} + V_i$ and similarly the secondary diagonals $e_i = -\frac{1}{h^2}$.
Having the quantum mechanical problem on matrix form we can use Jacobi's algorithm to solve it, and then compare the numerical eigenvalues to the analytical solutions $\lambda = 3, 7, 11, 15, \ldots$.

\subsection{Schrödingers Equation - Two Electrons in a Harmonic Oscillator Potential}

\label{sec:SEtwoelectron}
Another problem from quantum mechanics worth considering is the Coulomb interaction between two electrons in a three dimensional harmonic oscillator potential, which has analytical solutions usable for comparison.

When adding another electron to the earlier single-electron case, we also need to introduce the Coulomb interaction, resulting in the Schrödinger equation on the following form
\begin{align}
	&\left(-\frac{\hbar^2}{2m}\dv[2]{r_1} -\frac{\hbar^2}{2m}\dv[2]{r_2} + \frac{1}{2}kr_1^2 + \frac{1}{2}kr_2^2 + \frac{\beta e^2}{|\vec{r}_1 - \vec{r_2}|}\right)\nonumber\\
	&\cdot u(r_1,r_2)= E^{(2)}u(r_1,r_2).
\end{align}
Here the Coulomb potential $V_{coul} = \frac{\beta e^2}{|\vec{r}_1 - \vec{r_2}|}$ for $\beta e^2 = 1.44$ eVnm, the energy of the two electron system is $E^{(2)}$ and the positions of the electrons are given as $r_1$ and $r_2$. 

It is now convenient to introduce the relative distance $\vec{r} = \vec{r}_1 - \vec{r}_2$ and the center-of-mass $\vec{R} = \frac{1}{2}(\vec{r}_1 - \vec{r}_2)$ in order to split the Schrödinger equation in two by separation of variables, $u(r) = \psi(r)\phi(R)$. We now only consider the equation for $\psi(r)$ as the center-of-mass equation is simply another harmonic oscillator previously shown how to solve. We introduce a convenient scaling to make the equation dimensionless so as to solve it using Jacobi's algorithm. As this is completely analogous to the previously shown single-electron case we jump ahead to the final form of the dimensionless equation (See Appendix for detailed description of scaling and seperation of variables):
\begin{align}
-\dv[2]{\rho}\psi(\rho) + \omega_r^2\rho^2\psi(\rho) + \frac{1}{\rho} = \lambda\psi(\rho).
\end{align}
The frequency $\omega_r$ is a parameter directly linked to the strength of the harmonic oscillator potential. The discetization and reformulation as a matrix problem in this case is done completely analogously to the single electron case, this time using diagonal elements $d_i = \frac{2}{h^2} + V_i$ for $V_i = \omega_r^2\rho^2 + \frac{1}{\rho}$.

We are only interested in the ground state of the system, thus we let $l=0$. The system's ground state eigenvalues, found through the Jacobi algorithm, are then compared to the analytical solutions and the eigenstates are plotted for different strengths $\omega_r$ of the harmonic oscillator potential.

\section{Results} \label{sec:results}
The buckling beam equation, given by (\ref{eq:matrix_eq}) was solved using the Jacobi algorithm as described in section \ref{sec:Jacobi}. Plotting the relative error between the first three of the numerical eigenvalues and analytical eigenvalues given by (\ref{eq:analyticaleig}) as a function of increasing the grid size $n$ produced the result shown in Figure \ref{fig:relerr}. The number of similarity transforms needed are plotted as a function of matrix dimensions $n$ for the buckling beam problem. In this plot we compare it to the analytical function $f(n)=\frac{3}{2}n^2$ as well. This is shown in Figure \ref{fig:iteration}. The CPU-time for a complete run through of the Jacobi algorithm is also plotted as a function of matrix dimensions $n$.  This is shown in Figure \ref{fig:cputimes}\\\indent

\begin{figure*}[h]
	\plotone{{Figures/cputime}.eps}
	\caption{Figure showing the CPU-time as a function of matrix dimension $n$ when solving the buckling beam problem with the jacobi algorithm.}
	\label{fig:cputimes}
\end{figure*}
For the harmonic oscillator potential described in section \ref{sec:SEharmosc} the first four numerical eigenvalues were compared with the known analytical egenvalues for this problem, namely $3$, $7$, $11$ and $15$. Figure \ref{fig:rhomax} shows the absolute error of the first four eigenvalues compared with their analytical solutions as a function of the dimensionless maximum distance $\rho_{max}$. This result was achieved using a matrix of dimensions $n=400$ for each $\rho_{max}$.\\\indent
\begin{figure*}[h]
	\plotone{{Figures/rhoN_plots}.eps}
	\caption{Figure showing the absolute error of the first four eigenvalues for the harmonic oscillator potential described in section \ref{sec:SEharmosc} as a function of varying the dimensionless maximum distance $\rho_{max}$.}
	\label{fig:rhomax}
\end{figure*}
For the two electrons in a harmonic oscillator potential problem, as described in section \ref{sec:SEtwoelectron}, the first eigenstate is plotted as a function of $\rho$ for varying degrees of the potential strength $\omega_r$.  This is shown in Figure \ref{fig:eigenstates}. The ground state eigenvalues $\lambda_1$ for selected values for the potential strength $\omega_r$ are tabulated in Table \ref{tab:twoelectronenergy}.
\begin{figure*}[h]
	\plotone{{Figures/eigenstates}.eps}
	\caption{Figure showing the eigenvector for the ground state in the two electron harmonic oscillator potential as described in section \ref{sec:SEtwoelectron} for varying $\omega$.}
	\label{fig:eigenstates}
\end{figure*}

\begin{deluxetable}{rc}
	%\tablewidth{0pt}
	\tablecaption{Table showing a selection of potential strength and the corresponding ground state energy eigenvalues for the two electrons in harmonic oscillator potential problem. These results were produced with a grid size of $n=300$. \label{tab:twoelectronenergy}}
	%\tablecomments{}
	
	\tablecolumns{2}
	\tablehead{\hspace{0.15\columnwidth}$\omega_r$		\hspace{0.15\columnwidth}&\hspace{0.15\columnwidth} $\lambda_1$ \hspace{0.15\columnwidth}}
	\startdata
	$0.01$  & $0.420$   \\
	$0.05$ & $0.475$  \\
	$0.25$ & $1.250$   \\
	$0.5$ & $2.230$   \\
	$1$ & $2.058$ \\
	$5$ & $17.443$ 
	\enddata
\end{deluxetable}

\section{Discussion} \label{sec:discussion}
When solving the buckling beam problem using the Jacobi algorithm, the relative error between the analytical and numerical eigenvalues increases rapidly before it quickly settles on a constant relative error for the three eigenvalues considered. This is seen in Figure \ref{fig:relerr}. In our figure $n$ starts at $n=3$. For a $2\times2$ matrix the numerical result should reproduce the exact solution to machine precision. It is worth noting that difference between the constant settling value and the initial error is relatively small. We have set a tolerance for treating the off-diagonal elements as zero to $\epsilon=1e-8$.  The similarity transforms ends when the off-diagonal elements is below this threshold which is constant for every $n$. In order to further test this method, one could study the settling value as a function of $\epsilon$. It is also worth noting that we have only studied this behaviour up to $n=100$. This behaviour could change after further increasing $n$.
	When plotting the number of similarity transforms, as shown in Figure \ref{fig:iteration}, one can see that they increase exponentially as the grid size $n$ increases. Here we compare it to $f(n) =\frac{3}{2}n^2$ as it has a similar slope. This strongly indicates that the number of similarity transforms is proportional to $n^2$ as theory suggests. The CPU time shown in Figure \ref{fig:cputimes} shows the same behaviour as the number of similarity transforms plot. For a dense matrix the CPU time should behave proportionally to $n^3$. We have a tridiagonal matrix with a large number of values already set to zero. This can account for the deviation between the measured CPU time and the theoretical.\\\\\indent

The relative error between the numerical and analytical ground state energy eigenvalues of single electron in a harmonic oscillator potential as seen in Figure \ref{fig:rhomax} shows how the error behaves as a function of $\rho_{max}$ at a constant grid size $n = 400$. All four eigenvalues result in relative errors starting out quite high at between ten and 100. However, the relative error quickly decreases when approaching $\rho_{max}\in(4,6)$. Each graph has its minimum in this interval, but not at the same value. It is thus impossible to minimize the relative error for all four eigenvalues at the same time. One has to make a compromise (see dotted line). We found the best compromise to be at $\rho_{max}\approx 5.2$. At this value the fourth relative error graph is minimized and the remaining are all below the wanted precision of four digits. 

When further increasing $\rho_{max}$ the relative errors starts to grow again, as their minima are passed. This sugestes that for a grid size of $n = 400$ a sufficient approximation for an infinite radial distance is $\rho_{max} = 5.2$, as it is the value at which the relative error is at is smallest and at the same time below the set tolerance. Since the minima of the relative errors move upwards for increasing $\rho_{max}$ we cannot represent more than four eigenvalues to the wanted precision. In order to find more eigenvalues to the set tolerance we would thus have to increase the grid size $n$. Thus a further improvment would be to grid over both $n$ and $\rho_{max}$ to produce a contour plot of the relative error, illustrating the best combination of the two variables.\\\\\indent

For the two electron problem, as shown in Figure \ref{fig:eigenstates}, We can clearly see that when increasing the potential strength $\omega_r$ the wave function peaks closer to the origin, while spreading out more for lower $\omega_r$. This is consistent with expectations from quantum mechanics, as increasing $\omega_r$ decreases the width of the potential well, making it more probable to find the electrons closer to the center of the well at $\rho = 0$.

The ground state energies $\lambda_1$ seen in Table \ref{tab:twoelectronenergy} corresponding to the eigenstates shown in Figure \ref{fig:eigenstates} illustrate how the energy of the electrons behaves as a function of the potential strength $\omega_r$. Clearly the energy eigenstates increase in value when increasing the potential strength. Thus a steeper potential well increases the systems ground state energy. Furthermore, since we find that our numerical eigenvalues for $\omega_r = 0.25$ and $\omega_r = 0.05$ are consistent with the analytical ones found by \cite{taut:1993} (being about the same up to a factor 2 due to a different scaling; $\lambda_1^{\omega_r = 0.25} = 0.6250$ and $\lambda_1^{\omega_r = 0.05} = 0.175$), we conclude that our results are quite sound.

\section{Conclusion} \label{sec:conclusion}
We have implemented the Jacobi algorithm for finding eigenvalues and applied it to three physical problems. The numerical solutions provided by the algorithm were in agreement with values calculated analytically within an acceptable tolerance. The performance of the algorithm differed from what one would expect which reasonable due to the fact that the problems at hand provided tridiagonal matrices as oppose to dense matrices. For the harmonic oscillator potential problem our results were made with a constant $n$. A natural next step would be to make a grid over different combinations of $n$ and $\rho_{max}$ to find the optimal $\rho_{max}$ for a given matrix dimension.


\nocite{jensen:2019}
\bibliographystyle{aasjournal}
\bibliography{ref}

\begin{appendix}
Consider the two-electron Schrödinger equation 
\begin{align}
	\left(-\frac{\hbar^2}{2m}\dv[2]{r_1} -\frac{\hbar^2}{2m}\dv[2]{r_2} + \frac{1}{2}kr_1^2 + \frac{1}{2}kr_2^2 + \frac{\beta e^2}{|\vec{r}_1 - \vec{r_2}|}\right)
	\cdot u(r_1,r_2)= E^{(2)}u(r_1,r_2).
\end{align}

The next step in transforming the equation to dimensionless form is to introduce the relative distance $\vec{r} = \vec{r}_1 - \vec{r}_2$ and the center-of-mass $\vec{R} = \frac{1}{2}(\vec{r}_1 - \vec{r}_2)$ enabeling to us write the Schrödinger equation as
\begin{align}
\left(-\frac{\hbar^2}{m}\dv[2]{r} -\frac{\hbar^2}{4m}\dv[2]{R} + \frac{1}{4}kr^2 + kR^2 + \frac{\beta e^2}{r}\right)\cdot u(r,R)= E^{(2)}u(r,R).
\end{align}

Since the relative distance and the center-of-mass are two independent degrees of freedom, we can use separation of variables $u(r) = \psi(r)\phi(R)$ to isolate the Schrödinger equation for the relative distance. Since the center-of-mass equation is just a regular harmonic oscillator potential, similar to the one we solved earlier, we neglect it from here on. The energy of the two-electron system can then be separated too, as $E^{(2)} = E_r + E_R$, where $E_r$ is the energy of the relative distance equation and $E_R$ is the harmonic oscillator energy of the center-of-mass frame. 
The Schrödinger equation for the relative distance 
\begin{align}
	\left(-\frac{\hbar^2}{m}\dv[2]{r} + \frac{1}{4}kr^2 + \frac{\beta e^2}{r}\right)\psi(r) = E_r\psi(r),
\end{align}
can similarly to the single-electron case, be made dimensionless by introducing the dimensionless variable $\rho = r/\alpha$. 

This then gives the equation
\begin{align}
-\dv[2]{\rho}\psi(\rho) + \frac{1}{4}\frac{mk}{\hbar^2}\alpha^4\rho^2\psi(\rho) + \frac{m\alpha\beta e^2}{\rho\hbar^2}\psi(\rho) = \frac{m\alpha^2}{\hbar^2}E_r\psi(\rho).
\end{align}
In order to write it on a similar form to (\ref{eq:schrodinger_dimless}) we define the frequency 
\begin{align}
\omega_r^2 = \frac{1}{4}\frac{mk}{\hbar^2}\alpha^4,
\end{align}
where we require 
\begin{align}
\frac{m\alpha\beta e^2}{\hbar^2} = 1
\end{align}
introducing a new natural lengths scale 

\begin{align}
\alpha = \frac{\hbar^2}{m\beta e^2}.
\end{align}
Finally we let the energy eigenvalues be rewritten on dimensionless form 
\begin{align}
	\lambda = \frac{m\alpha^2}{\hbar^2}E,
\end{align}
resulting in the final form of the Schrödinger equation 
\begin{align}
-\dv[2]{\rho}\psi(\rho) + \omega_r^2\rho^2\psi(\rho) + \frac{1}{\rho} = \lambda\psi(\rho),
\end{align}
where $\omega_r$ is a parameter characterizing the harmonic oscillator.
\end{appendix}

\end{document}

