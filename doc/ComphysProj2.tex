
\documentclass[twocolumn]{aastex62}


\newcommand{\vdag}{(v)^\dagger}
\newcommand\aastex{AAS\TeX}
\newcommand\latex{La\TeX}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\begin{document}

\title{Project 2 FYS4150}




\author{Håkon Tansem}

\author{Nils-Ole Stutzer}

\author{Bernhard Nornes Lotsberg}

\begin{abstract}

\end{abstract}

\section{Introduction} \label{sec:intro}
When solving physical and mathematical problems, a reoccouring problem is to find eigenvalues of a matrix or an opperator. Since a wide variety of problems can be solved by setting up and solving eigenvalue equations it is, essential to develop efficient methods for finding eigenvalues. 

In this paper we will show how an eigenvalue solver implementing Jacobi's algorithm can be used to solve problems like the eigenmodes of the classical wave equation and the eigenenergies of the Schrödinger equation for one or two electron in a harmonic oscillator potential. Both problems can be rescaled in such a way that the resulting equations are on a dimensionless form, then being on a generalized form also representative for a variety of different eigenvalue problems from several different fields of science. We will explore how the numerical and analytical eigenvalues of the problems illustrated compare and how the run time of the Jacobi algorithm behaves when changing the grid size.   

\section{Method} \label{sec:method}
\subsection{Classical Wave - The Buckling Beam Problem}
The first example of an eigenvalue problem we show is the classical wave equation for a buckeling beam in one dimension
\begin{align}
	\gamma\dv[2]{u(x)}{x} = -F(x)u(x).
	\label{eq:beam_wave}
\end{align} 
Here $u(x)$ represents the vertical displacement of the beam along the $y$-direction. We let $x\in[0,L]$ for a beam length $L$. The constant $\gamma$ is a material dependent parameter specifying the beams regidity and $F$ is the force applyed at the interval $(0, L)$. Next the Dirichlet boundary conditions are imposed so that $u(0) = u(L) = 0$. We consider the three parameters $F$, $L$ and $\gamma$ as known.
In order to make the equation more convinient to handle, we scale the integration variable to the beam length as 
\begin{align}
	\rho = \frac{x}{L},
\end{align}
so that the new dimensionless integration variable $\rho\in[0, 1]$. We can now rewrite (\ref{eq:beam_wave}) as 
\begin{align}
	\dv[2]{u(\rho)}{\rho} = -\frac{FL^2}{\gamma}u(\rho) = -\lambda u(\rho),
	\label{eq:wave_eq_dimless}
\end{align}
where we define $\lambda = \frac{FL^2}{\gamma}$. In order to solve (\ref{eq:wave_eq_dimless}) for the $\lambda$'s numerically the discretisation $\rho\to\rho_i = \rho_0 + ih$ with $i = 0, 1, 2, 3, \ldots n-1$, is itroduced resulting in the discrete equation

\begin{align}
	\dv[2]{u_i}{x} &\approx
	-\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} = \lambda u_i ,
\end{align}
where the step length $h = \frac{\rho_n - \rho_0}{n}$, $\rho_0 = \rho_\text{min} = 0$ and $\rho_n = \rho_\text{max} = 1$ are the boundaries and $n$ is the grid size. Here $u_{i\pm1}$ denotes $u(\rho_i\pm h)$.

The above discrete equation can easily be fomulated as a matrix equation 
\begin{align}
	A\vec{u} = \lambda\vec{u},
	\label{eq:matrix_eq}
\end{align}
by introducing the vector $\vec{u}^T = [u_1, u_2, \ldots, u_{n-1}]$ and the matrix
\begin{align}
A = 
	\begin{bmatrix} 
	d& a & 0   & 0    & \dots  &0     & 0 \\
    a & d & a & 0    & \dots  &0     &0 \\
    0   & a & d & a  &0       &\dots & 0\\
    \dots  & \dots & \dots & \dots  &\dots      &\dots & \dots\\
    0   & \dots & \dots & \dots  &a  &d & a\\
   0   & \dots & \dots & \dots  &\dots       &a & d
    \end{bmatrix} ,
\end{align}
where $a = -\frac{1}{h^2}$ and $d = \frac{2}{h^2}$.
The problem is now transformed into a linear algebra eigenvalue problem.  Since the analytical eigenvalues 
\begin{align}\label{eq:analyticaleig}
	\lambda_i = d + 2a \cos\left(\frac{j\pi}{n+1}\right)\quad j = 1, 2, 3, \ldots n,
\end{align}
are known we can later compare these to those found numerically.

\subsection{Eigenvalue Solver - Jacobi's Algorithm}
\label{sec:Jacobi}
The eigenvalue solver we will show is using the Jacobi algorithm, which converges quite stabely yet very slowly. The essence of the algorithm is that we can rotate the column space of $A$ around different axis in the $n$ dimensional space using similarity transforms to obtain a diagonal matrix $D$ being similar to $A$. Due to the similarity between $D$ and $A$, the diagonal elements $d_ii = \lambda_i$ being the eigenvalues of $D$ are eigenvalues of $A$ too.

The similarity transforms used in the Jacobi algorithm is based on a sequence of orthogonal transforms. In an orthogonal transformation an orthogonal basis $F = \{\vec{v}_i | i = 1, 2, \ldots, n\}$, keeps its orthogonality. Meaning that the basis vectors in the new basis $G = \{\vec{w}_i | i = 1, 2, \ldots, n\}$ where $\vec{w}_i = U\vec{v}_i$ forms a new orthogonal basis for the same space as before the transformation, if $U$ is orthogonal i.e. $UU^T = U^TU = I_n$ giving $U^{-1} = U^T$. Therefore the inner product of basis vectors in $G$ give 
\begin{align}
	\vec{w}_i\cdot \vec{w}_j &= w_i^Tw_j = (Uv_i)^T(Uv_j) \\
	&= v_i^TU^TUv_j = v_i^Tv_j = \delta_{ij},
\end{align}
since $v_i^Tv_j = \delta_{ij}$ due to the orthogonality of the basis $F$.

When transforming $A$ into a diagonal matrix $D$ we need to eliminate the off-diagonal elements of $A$. This is done by similarity transform $B$ of $A$ is then written as  
\begin{align}
	B = S^T A S,
\end{align}
for a rotational matrix 
\begin{align}
S = 
	\begin{bmatrix}
		1 & 0 & 0 & 0 & \cdots & 0\\
		0 & 1 & 0 & 0 & \cdots & 0 \\	
		\vdots & & \ddots & & & \vdots \\
		0 & & \cos\theta & \cdots & \sin\theta & 0\\
		\vdots & & & & & \vdots \\
		0 & & -\sin\theta & \cdots & \cos\theta & 0\\
		\vdots & & \ddots & & & \vdots \\
		0 & 0 & 0 & 0 & 1 & 0\\		
		0 & 0 & 0 & 0 & 0 & 1
	\end{bmatrix},
\end{align}
rotating the column space basis an angle $\theta$ in the $\rho_k$-$\rho_l$-plane, since $S_{kk} = S_{ll} = \cos\theta = c$, $S_{kl} = \sin\theta = s = -S_{lk}$. Since the rotational matrix $S$ is orthogonal, the matrix $B$ is similar to $A$.

Multiplying out the above similarity transform we get 
\begin{align}
	b_{ii} &= a_{ii} , i\neq k, i\neq l\\
	b_{ik} &= a_{ik}c - a_{il}s, i\neq k, i\neq l\\
	b_{il} &= a_{il}c + a_{ik}s, i\neq k, i\neq l\\
	b_{kk} &= a_{kk}c^2 - 2a_{kl}cs + a_{ll}s^2\\
	b_{ll} &= a_{ll}c^2 + 2a_{kl}cs + a_{kk}s^2\\
	b_{kl} &= (a_{kk} - a_{ll})cs + a_{kl}(c^2 - s^2).
	\label{eq:b_kl}
\end{align}
Since we want to zero out the off-diagonals of $A$ we require that (\ref{eq:b_kl}) is zeroed out $b_{kl} = b_{lk} = 0$. Defining 
\begin{align}
	\cot(2\theta) = \tau = \frac{a_{ll} - a_{kk}}{2a_{kl}}
\end{align}
we get a quadratic equation $t^2 + 2\tau t - 1 = 0$, where $t = \tan \theta$, the requirement from $b_{kl} = 0$. From this quadratic equation we get that 
\begin{align}
	t &= -\tau \pm \sqrt{1+\tau^2}\\
	c & = \frac{1}{\sqrt{1+t^2}}\\
	s &= tc.
\end{align}
This way we can tune the angle $\theta$ in order to zero out $b_{kl}$ and then find the remaining elements of $B$.  Unfortunatlly the way $t$ is defined is numerically unstable. If $\tau\gg1$ a computer will let $1+\tau^2 = \tau^2$ resulting in $t = -\tau \pm \tau$ which is of course not correct. Using some simple algebra we rewrite $t = -\frac{1}{-\tau \pm \sqrt{1 + \tau^2}}$, which is more numerically stable. Choose to let $t = \frac{1}{\tau + \sqrt{1 + \tau^2}}$ whenever $\tau>0$ and let $t = -\frac{1}{-\tau + \sqrt{1+\tau^2}}$ when $t<0$, We circumvent the subtraction of almost equal numbers in the denominator resulting in division by zero.

As shown by (SITER KOMPENDIET TIL MORTEN HER) for a $2\time 2$-matrix w.l.o.g., the off-diagonal norm of a similarity transform $B$ is 
\begin{align}
\text{Off}(B)^2&= \sum_{i\neq j} |b_{ij}^2| = ||A||_F^2 - 2a_{kl},
\label{eq:Off_reduction}
\end{align}
being reduced in size for each transfrom. The question is now, which elements $a_{kl}$ should be eliminated each time we perform a similarity transform? This is best answered by looking at (\ref{eq:Off_reduction}); if we choose $a_{kl}$ to be the greatest off-diagonal element of $A$ we reduce $\text{Off}(B)^2$ by the greatest possible value for each iteration. 

Since we want to end up with a diagonal matrix $D$ we need to make the off-diagonal norm approach zero through multiple similarity transforms. In practice this corresponds to iterate over similarity transforms, until 
\begin{align}
\text{Off}(A) \geq \max_{i\neq j}(a_{ij}^2) = a_{kl}^2 \leq \epsilon,
\end{align}
for a tolerance $\epsilon$ typically $\sim 10^{-8}$. We can thus use 
$\max_{i\neq j}(a_{ij}^2)\leq \epsilon$ as a criterion for when to stop the similarity transforms, instead of calculating $\text{Off}(A)$ which is rather time consuming.

The \texttt{while}-loop iterating over the similarity transform thus stops when $\max_{i\neq j}(a_{ij}^2) \leq \epsilon$. After having looped over the similarity transforms the remaining matrix should be diagonal withing the tolerance, making it easy to extract the eigenvalues $\lambda_i$. In case we want to find the eigenvectors corresponding to the eigenvalues found, we simply rotate an arbritrary orthogonal basis for $\mathcal{R}^n$ for each loop iteration using the corresponding rotation $S$. We simply contain the input basis vectors in a matrix $E$, e.g. the identity matrix, and rotate them one rotation by multiplying $SE$. This is also done in the loop so that 
\begin{align}
	e_{ik} &= ce_{ik} - se_{il}\\
	e_{il} &= ce_{il} + se_{ik}.
\end{align}

As discussed by (SITER MORTENS KOMPENDIUM HER) the Jacobi algorithm usually requires between $3n^2-5n^2$ rotations, and each rotation has about $4n$ operations, resulting in $13n^3-20n^3$ operations to zero out the off-diagonal elements. Since we only consider sparse matrices in our case, we would expect $\sim n$ rotations needed to diagonalise. 

The Jacobi algorithm can now be used to solve eigenvalue problems for symmetrical matrices like the buckeling beam wave or quantum mechanical problems as shown in the following subsection. 

\subsection{Schrödinger's Equation - One Electron in a Harmonic Oscillator potential}

\label{sec:SEharmosc}
Next we show how to apply the Jacobi algorithm to find the energy eigenvalues of the Hamiltonian operator for an electron in a harmonic oscillator potential $V(r)$ in three dimensions. For simplicity we only consider the radial Schrödinger equation 
\begin{align}
-\frac{\hbar^2}{2m}\left(\frac{1}{r^2}\dv{r}r^2\dv{r} - \frac{l(l+1)}{r^2}\right)R(r) + V(r)R(r) = E R(r),
\end{align}
where $V(r) = \frac{1}{2}kr^2$ with $k = m\omega^2$, and the energies $E$ of the electron in the harmonic oscillator in three dimensions is given as 
\begin{align}
	E_{nl} = \hbar\omega\left(2n + l + \frac{3}{2}\right),
\end{align}
where $n = 0, 1, 2,\ldots$ and $l = 0, 1, 2, \ldots$. $n$ and $l$ represent the principal and orbital momentum quantum numbers. We let the radial distance $r\in[0,\infty)$. Next we let $R(r) = \frac{u(r)}{r}$ so that 
\begin{align}
	-\frac{\hbar^2}{2m}\dv[2]{r}u(r) + \left(V(r) + \frac{l(l+1)}{r^2}\frac{\hbar^2}{2m}\right)u(r) = Eu(r).
	\label{eq:u_r}
\end{align}
In order to reflect reality we must require $u(0) = u(\infty) = 0$, as the wave function of the electron must fall of to zero when going to infinity. 

To ensure a safer handling of the equation we introduce the dimensionless radial distance $\rho = \frac{r}{\alpha}$, where $\alpha$ is a parameter with dimension length. Inserting this into (\ref{eq:u_r}) we obtain
\begin{align}
	-\frac{\hbar^2}{2m\alpha^2}\dv[2]{\rho}u(\rho) + \left(V(\rho) + \frac{l(l+1)}{\rho^2}\frac{\hbar^2}{2m\alpha^2}\right)u(\rho) = Eu(\rho).
	\label{eq:schrodinger_rho}
\end{align}
To simplify things further we only consider the case where $l=0$. Then inserting the dimensionless potensial $V(\rho) = \frac{k}{2}\alpha^2\rho^2u(\rho)$ into (\ref{eq:schrodinger_rho}) we can rewrite the equation as 
\begin{align}
	-\frac{\hbar^2}{2m\alpha^2} \dv[2]{\rho} u(\rho) + \frac{k}{2}\alpha^2\rho^2u(\rho) = Eu(\rho),
\end{align}
by multiplying both sides by $\frac{2m\alpha^2}{\hbar^2}$.
In order to simplify things even further we introduce a natural length scale so that 
\begin{align}
	\alpha = \left(\frac{\hbar^2}{mk}\right)^{1/4},
\end{align}
being set by the mass of the electron $m$ and the strength potential $k$ and we let the frequency $\omega = 1$.
The energy eigenvalues are then defined as 
\begin{align}
	\lambda = \frac{2m\alpha^2}{\hbar^2}E.
\end{align}

The Schrödinger equation is now on a dimensionless form 
\begin{align}
	-\dv[2]{\rho}u(\rho) + \rho^2u(\rho) = \lambda u(\rho),
	\label{eq:schrodinger_dimless}
\end{align}
where $V(\rho)=\rho^2$ is now an effective potential.
In order to solve for the eigenvaules numerically we discretize the equation so that 
\begin{align}
	&-\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} + \rho_i^2 u_i \\
	&= -\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2} + V_iu_i = \lambda u_i, 
\end{align}
letting the effective potential $V_i = \rho_i^2$. The step size $h$ has the same form as shown earlier only for a different $\rho_n$. Since we need the wave function $u(\rho)$ to tent to zero at infinity, $\rho\to \infty$, we must set $\rho_{max} =\rho_n= \infty$. However, using a comuter to solve this eigenvalue problem it is impossible to let $\rho_{max} = \infty$, meaning we need to find a suitably large number to approximate infinity. The approximation of infinity will also be dependent on the matrix size, meaning we have to balance our choiced for the parameter $\rho_{max}$ and $n$ in order to acheive the wanted precision in the eigenvalues. Now, from this discritesiation we can write the equation on the same matrix form as (\ref{eq:matrix_eq}), only this time using diagonal elements $d_i = \frac{2}{h^2} + V_i$ and similarly the secondary diagonals $e_i = -\frac{1}{h^2}$.
Having the quamtum mechanical problem on matrix form we can use Jacobi's algorithm to solve it, and then compare the numerical eigenvalues to the analytical solutions $\lambda = 3, 7, 11, 15, \ldots$.

\subsection{Schrödingers Equation - Two Electrons in a Harmonic Oscillator potential}

\label{sec:SEtwoelectron}
Another problem from quantum mechanics worth considering is the Coulomb interaction between two electrons in a harmonic oscillator potential, in three dimensions, as this has an analytical solution we can use as comparison. 

When adding another electron to the earlier single-electron case, we need to introduce the Coulomb interaction too, giving the Schrödinger equation 
\begin{align}
	&\left(-\frac{\hbar^2}{2m}\dv[2]{r_1} -\frac{\hbar^2}{2m}\dv[2]{r_2} + \frac{1}{2}kr_1^2 + \frac{1}{2}kr_2^2 + \frac{\beta e^2}{|\vec{r}_1 - \vec{r_2}|}\right)\nonumber\\
	&\cdot u(r_1,r_2)= E^{(2)}u(r_1,r_2).
\end{align}
Here the Coulomb potential $V_{coul} = \frac{\beta e^2}{|\vec{r}_1 - \vec{r_2}|}$ for $\beta e^2 = 1.44$ eVnm, the energy of the twoelectrons system is $E^{(1)}$ and the positions of the electrons are given as $r_1$ and $r_2$. 

It is now convinient to introduce the relative distance $\vec{r} = \vec{r}_1 - \vec{r}_2$ and the centre-of-mass $\vec{R} = \frac{1}{2}(\vec{r}_1 - \vec{r}_2)$ in order to split the Schrödinger equation into two by seperation of variables, $u(r) = \psi(r)\phi(R)$. We from now on only consider the relative distance equation for $\psi(r)$ as the centre-of-mass equation is simply another harmonic oscillator previously shown how to solve. Then we introduce a convinient scaling to make the equation dimensionless so as to solve it using Jacobi's algorithm. As this is completely analogous to the previously shown single-electron case we jump ahead to the final form of the dimensionless equation (See Appendix for detailed description of scaling and seperation of variables):
\begin{align}
-\dv[2]{\rho}\psi(\rho) + \omega_r^2\rho^2\psi(\rho) + \frac{1}{\rho} = \lambda\psi(\rho).
\end{align}
The frequency $\omega_r$ is a parameter directly linked to the strength of the harmonic oscillator potential. The discetisation and reformulation as a matrix problem in this case is done completely analogous to the previously shown examples, this time using diagonal elements $d_i = \frac{2}{h^2} + V_i$ for $V_i = \omega_r^2\rho^2 + \frac{1}{\rho}$.

We are case only intrested in the ground state of the system, thus we let $l=0$. The systems ground state eigenvalues, found through the Jacobi algorithm, are then compared to the analytical solutions and the eigenstates are plotted for different choices of the potential strength $\omega_r$. 

\section{Results} \label{sec:results}
The buckling beam equation, given by equation (\ref{eq:matrix_eq}) was solved using the Jacobi algorithm as described in section \ref{sec:Jacobi}. Plotting the relative error between the first three of the numerical eigenvalues and analytical eigenvalues given by equation (\ref{eq:analyticaleig}) as a function of increasing the grid size $N$ produced the result shown in Figure \ref{fig:relerr}.\\\indent
\begin{figure*}[h]
	\plotone{{Figures/eigenrelerr}.eps}
	\caption{Figure showing the relative error between the numerical and analytical eigenvalues given by equation \ref{eq:analyticaleig} for the buckling beam problem given by \ref{eq:matrix_eq}. }
	\label{fig:relerr}
\end{figure*}
For the harmonic oscillator potential described in section \ref{sec:SEharmosc} the first four numerical eigenvalues were compared with the known analytical egenvalues for this problem, namely $3$, $7$, $11$ and $15$. Figure \ref{fig:rhomax} shows the absolute error of the first four eigenvalues compared with their analytical solutions as a function of the dimensionless maximum distance $rho_{max}$. This result was achieved using a matrix of dimensions $400x400$ for each $\rho_{max}$.\\\indent
\begin{figure*}[h]
	\plotone{{Figures/iteration}.eps}
	\caption{Figure showing the number of similarity transforms conducted before the off-diagonal elements are set below a tolerance when solving the buckling beam problem using the Jacobi algorithm.}
	\label{fig:iteration}
\end{figure*}
\begin{figure*}[h]
	\plotone{{Figures/cputime}.eps}
	\caption{Figure showing the CPU time as a function of matrix dimension $N$ when solving the buckling beam problem with the jacobi algorithm. The data is compared with the analytical function $f(N)=\frac{3}{2}N^2$.}
	\label{fig:cputimes}
\end{figure*}
The number similarity transforms that had to be conducted was plotted as a function of matrix dimensions $N$ for the buckling beam problem. In this plot we compared it to the analytical function $f(N)=\frac{3}{2}N^2$. This is shown in Figure \ref{fig:iteration}. The cpu time for a complete run through of the Jacobi algorithn was also plotted as a function of matrix dimensions $N$.  This is shown in Figure \ref{fig:cputimes}. For the harmonic oscillator potential described in section \ref{sec:SEharmosc} the first four numerical eigenvalues were compared with the known analytical egenvalues for this problem, namely $3$, $7$, $11$ and $15$. Figure \ref{fig:rhomax} shows the absolute error of the first four eigenvalues compared with their analytical solutions as a function of the dimensionless maximum distance $rho_{max}$. This result was achieved using a matrix of dimensions $N=400$ for each $\rho_{max}$.\\\indent
\begin{figure*}[h]
	\plotone{{Figures/rhoN_plots}.eps}
	\caption{Figure showing the absolute error of the first four eigenvalues for the harmonic oscillator potential described in section \ref{sec:SEharmosc} as a function of varying the dimensionless maximum distance $\rho_{max}$.}
	\label{fig:rhomax}
\end{figure*}
For the two electrons in a harmonic oscillator potential problem, as described in section \ref{sec:SEtwoelectron}, the first eigenstate was plotted as a function of $\rho$ for varying degree of the potential strength $\omega_r$.  This is shown in Figure \ref{fig:eigenstates}. The ground state eigenvalues $\lambda_1$ for selected values for the potential strength $\omega_r$ are tabulated in \ref{tab:twoelectronenergy}.
\begin{figure*}[h]
	\plotone{{Figures/eigenstates}.eps}
	\caption{Figure showing the eigenvector for the ground state in the two electron harmonic oscillator potential as described in section \ref{sec:SEtwoelectron} for varying $\omega$}
	\label{fig:eigenstates}
\end{figure*}
\begin{deluxetable}{lccc}
	%\tablewidth{0pt}
	\tablecaption{Table showing a selection of potential strength and the corresponding ground state energy eigenvalues for the two electrons in harmonic oscillator potential problem. These results were produced with a grid size of $N=300$. \label{tab:twoelectronenergy}}
	%\tablecomments{}
	\tablecolumns{2}
	\tablehead{$\omega_r$  &  $\lambda_1$ & }
	\startdata
	$0.01$  & $0.420$   \\
	$0.05$ & $0.475$  \\
	$0.25$ & $1.250$   \\
	$0.5$ & $2.230$   \\
	$1$ & $2.058$ \\
	$5$ & $17.443$ 
	\enddata
\end{deluxetable}

\section{Discussion} \label{sec:discussion}
When solving the buckling beam problem using the Jacobi algorithm, the relative error between the analytical and numerical eigenvalues increases rapidly before it quickly settles on a constant relative error for the three eigenvalues considered as seen in Figure \ref{fig:relerr}. It worth noting that difference between the constant settling value and the initial error is relatively small. For a $2\times2$ matrix the numerical result should reproduce the exact solution to machine precision. However we have set a tolerance for treating the off-diagonal elements as zero to $\epsilon=1e-8$.  This can be a source for error. When increasing the grid size and approaching a constant relative error, we approximate the system to a higher precision, in which should result in a IKKE FERDIG GITT\\\\\indent

When plotting the number of similarity transforms, as shown in Figure \ref{fig:iteration}, one can see that they increase exponentially as the grid size $N$ increases. Here we compare it to $f(N) =\frac{3}{2}N^2$ as it has a similar slope. This strongly indicates that the number of similarity transforms is proportional to $N^2$ as theory suggests. The CPU time shown in figure \ref{fig:cputimes} shows the same behaviour as the number of similarity transforms plot. For a dense matrix the cpu time should behave proprtional to $n^3$. We have a tridiagonal matrix with a large number of values already set to zero. This can account for the deviation between the measured CPU time and the theoretical.  


\section{Conclusion} \label{sec:conclusion}
The relative error between the numerical and analytical ground state energy eigenvalues of single electron in a harmonic oscillator potential as seen in Figure \ref{fig:rhomax} shows how the error behaves as a function of $\rho_{max}$ at a constant grid size $N = 400$. All four eigenvalues result in relative errors starting out quite high at between 10 and 100. However, the relative error quickly decreases when approaching $rho_{max}\in(4,6)$. Each graph has its minimum in this interval, but not at the same value. It is thus impossible to minimize the relative error for all four eigenvalues at the same time, only enabeling a compromise (see dotted line). We found the best compromise to be at $\rho_{max}\approx 5.2$. At this value the fourth relative error graph is minimized and the remaining are all below the wanted precision of four digits. 

When further increasing $\rho_{max}$ the relative errors again start to grow, as their minima are passed. This sugestes that for a gridsize $N = 400$ a sufficient approximation for an infinit radial distance is $\rho_{max} = 5.2$, as it is the value at which the relative error is at is smallest and at the same time below the set tolerance. Since the minima of the relative errors move upwards for increasing $\rho_{max}$ we cannot represent more than four eigenvalues to the wanted precision. In order to find more eigenvalues to the set tolerance we would thus have to increas the grid size $N$. Thus a further improvment would be to grid over both $N$ and $\rho_{max}$ to produce a contour plot of the relative error, illustrating the best combination of the two griding variables.

Next we introduced another electron to the harmonic oscillator, also taking into account the Coulomb interaction between those. The resulting ground state wave functions can be seen in Figure \ref{fig:eigenstates}, for several different potential strengths. We can clearly see that when increasing the potential strength $\omega_r$ the wave function peaks closer to the origin, while spreading out more for lower $\omega_r$. This is consistant with expectations from quantum mechanics, as increasing $\omega_r$ deacreases the width of the potential well, making it more probable to find the electrons closer to the centre of the well at $\rho = 0$.

The ground state energies $\lambda$ seen in Table \ref{tab:twoelectronenergy} corresponding to the eigenstates shown in Figure \ref{fig:eigenstates} illustrate how the energy of the electrons behaves as a function of the potential strength $\omega_r$. Clearly the energy eigenstates increase in value when increasing the potential strength. Thus a steeper potential well increases the systems ground state energy. Furthermore, since we find that our numerical eigenvalues for $\omega_r = 0.25$ and $\omega_r = 0.05$ are consistant to the analytical ones found by \cite{taut:1993} (being about the same up to a factor 2 due to a different scaling; $\lambda_1^{\omega_r = 0.25} = 0.6250$ and $\lambda_1^{\omega_r = 0.05} = 0.175$), we conclude that our results are quite sound.

\section{Conclusion} \label{sec:conclusion}

\bibliographystyle{aasjournal}
\bibliography{ref}

\begin{appendix}
Consider the two-electron Schrödinger equation 
\begin{align}
	&\left(-\frac{\hbar^2}{2m}\dv[2]{r_1} -\frac{\hbar^2}{2m}\dv[2]{r_2} + \frac{1}{2}kr_1^2 + \frac{1}{2}kr_2^2 + \frac{\beta e^2}{|\vec{r}_1 - \vec{r_2}|}\right)\nonumber\\
	&\cdot u(r_1,r_2)= E^{(2)}u(r_1,r_2).
\end{align}

The next step in transforming the equation to dimensionless form is to introduce the relative distance $\vec{r} = \vec{r}_1 - \vec{r}_2$ and the centre-of-mass $\vec{R} = \frac{1}{2}(\vec{r}_1 - \vec{r}_2)$ enabeling to write the Schrödinger equation as
\begin{align}
&\left(-\frac{\hbar^2}{m}\dv[2]{r} -\frac{\hbar^2}{4m}\dv[2]{R} + \frac{1}{4}kr^2 + kR^2 + \frac{\beta e^2}{r}\right)\nonumber\\
	&\cdot u(r,R)= E^{(2)}u(r,R).
\end{align}

Since the relative distance and the centre-of-mass are to independent degrees of freedom, we can use seperation of variables $u(r) = \psi(r)\phi(R)$ to isolate the Schrödinger equation for the relative distance. Since the centre-of-mass equation is just a regular harmonic oscillator potential, similar to the one we solved earlier, we neglect it from here on. The energy of the two-electron system can then be seperated too, as $E^{(2)} = E_r + E_R$, where $E_r$ is the energy of the relative distance equation and $E_R$ is the harmonic oscillator energy of the centre-of-mass frame. 
The Schrödinger equation for the relative distance 
\begin{align}
	\left(-\frac{\hbar^2}{m}\dv[2]{r} + \frac{1}{4}kr^2 + \frac{\beta e^2}{r}\right)\psi(r) = E_r\psi(r),
\end{align}
can similarly to the single-eectrone case, be made dimensionless by inroducing and itroducing the dimensionless variable $\rho = r/\alpha$. 

This then gives the equation
\begin{align}
-\dv[2]{\rho}\psi(\rho) + \frac{1}{4}\frac{mk}{\hbar^2}\alpha^4\rho^2\psi(\rho) + \frac{m\alpha\beta e^2}{\rho\hbar^2}\psi(\rho) = \frac{m\alpha^2}{\hbar^2}E_r\psi(\rho).
\end{align}
In order to write it on a similar form to (\ref{eq:schrodinger_dimless}) we define the frequency 
\begin{align}
\omega_r^2 = \frac{1}{4}\frac{mk}{\hbar^2}\alpha^4,
\end{align}
where we require 
\begin{align}
\frac{m\alpha\beta e^2}{\hbar^2} = 1
\end{align}
introducing a new natural lengths scale 

\begin{align}
\alpha = \frac{\hbar^2}{m\beta e^2}.
\end{align}
Finally we let the energy eigenvalues be rewritten on a dimensionless form 
\begin{align}
	\lambda = \frac{m\alpha^2}{\hbar^2}E,
\end{align}
resulting in the final form of the Schrödinger equation 
\begin{align}
-\dv[2]{\rho}\psi(\rho) + \omega_r^2\rho^2\psi(\rho) + \frac{1}{\rho} = \lambda\psi(\rho).
\end{align}
, where $\omega_r$ is a parameter characterizing the harmonic oscillator.
\end{appendix}

\end{document}
% End of file `sample62.tex'.